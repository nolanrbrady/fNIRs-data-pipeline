{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5d9cdf-a998-4e06-af13-2a2d09e96566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porting over the matlab code into python to see if we can reproduce results with the MNE library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a550b38-9e16-4193-8bf5-d2956d6c3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "# Import MNE processing\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from mne import Epochs, events_from_annotations, set_log_level\n",
    "\n",
    "# Import MNE-NIRS processing\n",
    "import mne\n",
    "from mne_nirs.channels import get_long_channels\n",
    "from mne_nirs.channels import picks_pair_to_idx\n",
    "from mne_nirs.datasets import fnirs_motor_group\n",
    "from mne.preprocessing.nirs import beer_lambert_law, optical_density,\\\n",
    "    temporal_derivative_distribution_repair, scalp_coupling_index\n",
    "from mne_nirs.signal_enhancement import enhance_negative_correlation\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import MNE-BIDS processing\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "\n",
    "# Import StatsModels\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Import Plotting Library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "529511ba-566b-4ce1-ba9f-7b3abbbbfe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip for using machine learning for exploratory type data analysis\n",
    "\n",
    "# Use principal component analysis (PCA) or independent component analysis (ICA), \n",
    "# to identify patterns in the fNIRS data that are not immediately obvious. \n",
    "# This can be used to identify latent neural networks or to identify different sources of signal variation.\n",
    "\n",
    "# ==========================================================\n",
    "\n",
    "# I'm curious how we could incorportate these into the data analsyis pipeline\n",
    "\n",
    "# Anomaly detection\n",
    "# Unsupervised learning algorithms such as one-class SVM, Autoencoder, and Isolation Forest can be used to identify outliers or abnormal patterns in the data.\n",
    "\n",
    "# Time-series analysis\n",
    "# Techniques such as time-series decomposition, ARIMA, and LSTM can be used to analyze the temporal dynamics of the fNIRS data and identify trends or patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4d5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurring values that we will keep the same\n",
    "\n",
    "# Length of the measured interval\n",
    "interval_length = 15\n",
    "# How you would like to rename the numeric triggers from Aurora\n",
    "trigger_id = {'4': 'Control', '2': 'Neutral', '3': 'Inflammatory', '1':'Practice'}\n",
    "# What files would you like to ignore while looping through subjects\n",
    "ignore = [\".DS_Store\", \"sub-03\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2ae24",
   "metadata": {},
   "source": [
    "# Analyze Each Subjects Data Individually and Return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbca4bb-6c98-487b-9a8a-9832eed8debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_analysis(bids_path):\n",
    "    \n",
    "    # Read data with annotations in BIDS format\n",
    "    # raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n",
    "    raw_intensity = mne.io.read_raw_snirf(bids_path, verbose=True, preload=False)\n",
    "    raw_intensity = get_long_channels(raw_intensity, min_dist=0.01)\n",
    "    \n",
    "    channel_types = raw_intensity.copy()\n",
    "    # print(channel_types)\n",
    "    \n",
    "    raw_intensity.annotations.rename(trigger_id)\n",
    "\n",
    "    # Convert signal to optical density and determine bad channels\n",
    "    raw_od = optical_density(raw_intensity)\n",
    "    sci = scalp_coupling_index(raw_od, h_freq=1.35, h_trans_bandwidth=0.1)\n",
    "    raw_od.info[\"bads\"] = list(compress(raw_od.ch_names, sci < 0.5))\n",
    "\n",
    "    # Down sample and apply signal cleaning techniques\n",
    "    raw_od.resample(0.8)\n",
    "    raw_od = temporal_derivative_distribution_repair(raw_od)\n",
    "\n",
    "    # Convert to haemoglobin and filter\n",
    "    raw_haemo = beer_lambert_law(raw_od, ppf=0.1)\n",
    "    raw_haemo = raw_haemo.filter(0.02, 0.3,\n",
    "                                 h_trans_bandwidth=0.1, l_trans_bandwidth=0.01,\n",
    "                                 verbose=False)\n",
    "\n",
    "    # Apply further data cleaning techniques and extract epochs\n",
    "    raw_haemo = enhance_negative_correlation(raw_haemo)\n",
    "    # Extract events but ignore those with\n",
    "    # the word Ends (i.e. drop ExperimentEnds events)\n",
    "    events, event_dict = events_from_annotations(raw_haemo, verbose=False)\n",
    "    \n",
    "    # Remove all STOP triggers to hardcode duration to 30 secs per MNE specs\n",
    "    events = events[::2]\n",
    "    # print(events)\n",
    "\n",
    "    epochs = Epochs(raw_haemo, events, event_id=event_dict, tmin=-1, tmax=15,\n",
    "                    reject=dict(hbo=200e-6), reject_by_annotation=True,\n",
    "                    proj=True, baseline=(None, 0), detrend=0,\n",
    "                    preload=True, verbose=False)\n",
    "\n",
    "    return raw_haemo, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873279e7",
   "metadata": {},
   "source": [
    "# Loop through subjects for individual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4dfaa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'sub-06', 'sub-07', 'sub-05', 'sub-03']\n",
      "Loading /Users/nolanbrady/Desktop/fNIRs-data-pipeline/python/../../LabResearch/IndependentStudy/DataAnalysis/BIDS_Anon/sub-06/nirs/sub-06_task-AnonCom_nirs.snirf\n",
      "Reading 0 ... 18357  =      0.000 ...  1804.493 secs...\n",
      "Loading /Users/nolanbrady/Desktop/fNIRs-data-pipeline/python/../../LabResearch/IndependentStudy/DataAnalysis/BIDS_Anon/sub-07/nirs/sub-07_task-AnonCom_nirs.snirf\n",
      "Reading 0 ... 17824  =      0.000 ...  1752.099 secs...\n",
      "Loading /Users/nolanbrady/Desktop/fNIRs-data-pipeline/python/../../LabResearch/IndependentStudy/DataAnalysis/BIDS_Anon/sub-05/nirs/sub-05_task-AnonCom_nirs.snirf\n",
      "Reading 0 ... 17061  =      0.000 ...  1677.096 secs...\n",
      "defaultdict(<class 'list'>, {'Control': [<Evoked | 'Control' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Control' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Control' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>], 'Inflammatory': [<Evoked | 'Inflammatory' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Inflammatory' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Inflammatory' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>], 'Neutral': [<Evoked | 'Neutral' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Neutral' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Neutral' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>], 'Practice': [<Evoked | 'Practice' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Practice' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>, <Evoked | 'Practice' (average, N=3), -1.25 – 15 sec, baseline -1.25 – 0 sec, 36 ch, ~163 kB>]})\n"
     ]
    }
   ],
   "source": [
    "all_evokeds = defaultdict(list)\n",
    "\n",
    "root_dir = '../../LabResearch/IndependentStudy/DataAnalysis'\n",
    "\n",
    "subjects = os.listdir(f'{root_dir}/BIDS_Anon/')\n",
    "\n",
    "print(subjects)\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub not in ignore:\n",
    "        # Create path to file based on experiment info\n",
    "        f_path = f'{root_dir}/BIDS_Anon/{sub}/nirs/{sub}_task-AnonCom_nirs.snirf'\n",
    "\n",
    "        # Analyse data and return both ROI and channel results\n",
    "        raw_haemo, epochs = individual_analysis(f_path)\n",
    "\n",
    "        for cidx, condition in enumerate(epochs.event_id):\n",
    "            all_evokeds[condition].append(epochs[condition].average())\n",
    "\n",
    "print(all_evokeds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6787726",
   "metadata": {},
   "source": [
    "# Extract Evoked Amplitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da45637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['ID', 'Chroma', 'Condition', 'Value'])\n",
    "temporal_measurements = []\n",
    "\n",
    "for idx, evoked in enumerate(all_evokeds):\n",
    "    subj_id = 0\n",
    "    for subj_data in all_evokeds[evoked]:\n",
    "        subj_id += 1\n",
    "        # can be either \"hbo\", \"hbr\", or both\n",
    "        for chroma in [\"hbo\", \"hbr\"]:\n",
    "            data = deepcopy(subj_data)\n",
    "            value = data.crop(tmin=-1, tmax=15).data * 1.0e6\n",
    "\n",
    "            # Reshape the data to be a flat numpy array\n",
    "            value = np.reshape(value, -1)\n",
    "            temporal_measurements.append(value)\n",
    "\n",
    "            # Placeholder while we see if PCA gives better results\n",
    "            avg_val = data.crop(tmin=-1, tmax=15).data.mean() * 1.0e6\n",
    "\n",
    "            # Append metadata and extracted feature to dataframe\n",
    "            this_df = pd.DataFrame(\n",
    "                {'ID': subj_id, 'Chroma': chroma, 'Condition': evoked, 'Value': avg_val}, index=[0])\n",
    "            df = pd.concat([df, this_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# df.reset_index(inplace=True, drop=True)\n",
    "df['Value'] = pd.to_numeric(df['Value'])  # some Pandas have this as object\n",
    "\n",
    "# You can export the dataframe for analysis in your favorite stats program\n",
    "# df.to_csv(\"stats-export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44e66d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 504)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temporal_measurements\n",
    "# df\n",
    "temporal_measurements = np.array(temporal_measurements)\n",
    "temporal_measurements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ddb9ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (24, 504), indices imply (24, 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/0f3gmdgs0db0f5gf8gg2874c0000gn/T/ipykernel_79510/267620887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Column-{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmeasurements_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemporal_measurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmeasurements_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 )\n\u001b[1;32m    693\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (24, 504), indices imply (24, 24)"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "for i in range(len(temporal_measurements)):\n",
    "    print(i)\n",
    "    columns.append(f'Column-{i}')\n",
    "\n",
    "measurements_df = pd.DataFrame(temporal_measurements, columns=columns)\n",
    "measurements_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d326afe",
   "metadata": {},
   "source": [
    "# Use PCA in order to reduce the number of points in the temporal readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e013d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Chroma</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Control</td>\n",
       "      <td>21.004154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Control</td>\n",
       "      <td>21.004154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Control</td>\n",
       "      <td>-101.936464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Control</td>\n",
       "      <td>-101.936464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Control</td>\n",
       "      <td>19.412607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Control</td>\n",
       "      <td>19.412607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>18.501778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>18.501778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>2.624723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>2.624723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>-282.158025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Inflammatory</td>\n",
       "      <td>-282.158025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>31.983615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>31.983615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-92.949621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-92.949621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>11.288993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>11.288993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Practice</td>\n",
       "      <td>14.782752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Practice</td>\n",
       "      <td>14.782752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Practice</td>\n",
       "      <td>-8.904012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Practice</td>\n",
       "      <td>-8.904012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>hbo</td>\n",
       "      <td>Practice</td>\n",
       "      <td>366.349501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>hbr</td>\n",
       "      <td>Practice</td>\n",
       "      <td>366.349501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Chroma     Condition       Value\n",
       "0   1    hbo       Control   21.004154\n",
       "1   1    hbr       Control   21.004154\n",
       "2   2    hbo       Control -101.936464\n",
       "3   2    hbr       Control -101.936464\n",
       "4   3    hbo       Control   19.412607\n",
       "5   3    hbr       Control   19.412607\n",
       "6   1    hbo  Inflammatory   18.501778\n",
       "7   1    hbr  Inflammatory   18.501778\n",
       "8   2    hbo  Inflammatory    2.624723\n",
       "9   2    hbr  Inflammatory    2.624723\n",
       "10  3    hbo  Inflammatory -282.158025\n",
       "11  3    hbr  Inflammatory -282.158025\n",
       "12  1    hbo       Neutral   31.983615\n",
       "13  1    hbr       Neutral   31.983615\n",
       "14  2    hbo       Neutral  -92.949621\n",
       "15  2    hbr       Neutral  -92.949621\n",
       "16  3    hbo       Neutral   11.288993\n",
       "17  3    hbr       Neutral   11.288993\n",
       "18  1    hbo      Practice   14.782752\n",
       "19  1    hbr      Practice   14.782752\n",
       "20  2    hbo      Practice   -8.904012\n",
       "21  2    hbr      Practice   -8.904012\n",
       "22  3    hbo      Practice  366.349501\n",
       "23  3    hbr      Practice  366.349501"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to figure out how to check if the PCA was effective or not.\n",
    "# Should we use a scaler in this instance or not?\n",
    "# I'm also concerned that HBO and HBR are the same for each subject...seems completely wrong.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(temporal_measurements)\n",
    "\n",
    "scaler.transform(temporal_measurements)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "reduced_measurements = pca.fit_transform(temporal_measurements)\n",
    "\n",
    "df['Value'] = reduced_measurements\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0291b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fc5cc4d1af0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the Data\n",
    "sns.catplot(x=\"Condition\", y=\"Value\", hue=\"ID\", data=df.query(\"Chroma == 'hbo'\"), ci=None, palette=\"muted\", height=4, s=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2aa5f1b5ca69a60e01984faab9e760efb8a58fb8834cef697905bc9b343526e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
